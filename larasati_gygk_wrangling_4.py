# -*- coding: utf-8 -*-
"""larasati-gygK-wrangling-4

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t985BhiSWcd0wq45EW3dn7aOjS43aDwz

# Tugas Wrangling 4

* Silakan download dan kerjakan soal berikut dimanapun (laptop pribadi/google colab/etc.)
* Setelah selesai mengerjakan, upload file ini di tempat yang telah disediakan pada platform.
* Beri nama file seperti berikut: {username}-wrangling-4.ipynb
* Contoh: johndoe-ab12-wrangling-4.ipynb
* Tutorial: https://discourse.pacmann.ai/t/pengumuman-seluruh-platform-pacmann-ai/409
* Username dapat dilihat di dalam akun anda.
* Mohon jangan mengubah nama variabel yang telah diberikan.
* Namun anda diperbolehkan untuk menambah variabel apapun.
---

# Wrangling Task 4

* Please download and work on the following questions (personal laptop/google colab/etc.)
* After finishing work, upload this file in the space provided on the platform.
* Name the file as follows: {username}-wrangling-4.ipynb
* Example: johndoe-ab12-wrangling-4.ipynb
* Tutorial: https://discourse.pacmann.ai/t/pengumuman-whole-platform-pacmann-ai/409
* Username can be seen in your account.
* Please do not change the given variable name.
* However you are allowed to add any variables.
---
"""

import pandas as pd
import numpy as np
from sklearn import preprocessing
from sklearn.preprocessing import normalize

"""Saat ini anda bekerja sebagai pegawai magang di salah satu perusahaan jual beli mobil bekas. Perusahaan ingin membuat sebuah fitur yang dapat memprediksi  harga mobil yang dimasukkan ke dalam website berdasarkan keterangan spesifikasi mobilnya.

Atasan anda memberikan tugas kepada anda untuk melakukan proses pembersihan data yang telah dikumpulkan dari website tersebut. Untuk memudahkan pekerjaan anda diberikan petunjuk pemrosesan data yang perlu dilakukan.

---

You are currently working as an intern at a used car buying and selling company. The company wants to create a feature that can predict the price of a car that is entered into the website based on the description of the car's specifications.

Your supervisor assigns you the task to carry out the process of cleaning the data that has been collected from the website. To facilitate your work, instructions for data processing are provided.

data yang akan diproses disimpan di dalam folder data dengan nama file `autos.csv`

---
the data to be processed is stored in the data folder with the file name `autos.csv`
"""

# FIX THE BROKEN CSV -- ONLY RUN IT ONCE
path =  'data/autos.csv'

car_test = pd.read_csv(path, encoding='ISO-8859-1')
car_test.to_csv(path, encoding='utf-8', index=False)

# REUPLOAD TO CONVERT FIXED CSV INTO UTF-8
# upload csv data into UTF-8
cars_data = pd.read_csv('data/autos.csv', encoding='utf-8')

"""### 1. Lakukan observasi untuk mengecek:
    1. 10 Data teratas
    2. Statistik dari tiap kolom
    3. Tipe data dari tiap kolom
    4. Persentase nilai null
---
1. Make observations to check:
     1. Top 10 data (head)
     2. Statistics of each column
     3. The data type of each column
     4. Percentage of null values
"""

# 1 # Get 10 first data
cars_data.head(10)

# 2 # Statistik tiap kolom
cars_data.describe(include="all")

# 3 # INFORMATION of data type per column
cars_data.info()

# 4 # PERSENTASE NILAI NULL
ColumnNullPerc = cars_data.isnull().sum()/len(cars_data) * 100
TotalNullPerc = cars_data.isnull().sum().sum()/len(cars_data) * 100
print()
print(ColumnNullPerc)
print()
print(TotalNullPerc)

"""### 2. ubahlah format penulisan beberapa kolom dari camelCase menjadi snake_case.

---

2. change the writing format of several columns from camelCase to snake_case.
   
   `"dateCreated": "ad_created"
    "dateCrawled": "date_crawled"
    "fuelType": "fuel_type"
    "lastSeen": "last_seen"
    "monthOfRegistration": "registration_month"
    "notRepairedDamage": "unrepaired_damage"
    "nrOfPictures": "num_of_pictures"
    "offerType": "offer_type"
    "postalCode": "postal_code"
    "powerPS": "power_ps"
    "vehicleType": "vehicle_type"
    "yearOfRegistration": "registration_year"`
"""

# Manual conversion from camel into snake
cars_data = cars_data.rename(
    columns={
      "dateCreated": "ad_created",
      "dateCrawled": "date_crawled",
      "fuelType": "fuel_type",
      "lastSeen": "last_seen",
      "monthOfRegistration": "registration_month",
      "notRepairedDamage": "unrepaired_damage",
      "nrOfPictures": "num_of_pictures",
      "offerType": "offer_type",
      "postalCode": "postal_code",
      "powerPS": "power_ps",
      "vehicleType": "vehicle_type",
      "yearOfRegistration": "registration_year"
    }
)

# SANITY CHECK
cars_data.head(5)

"""### 3. Ubah tipe data dari kolom yang berisi data tanggal sehingga bertipe data `datetime64`

---
3. Change the data type of the column containing date data so that the data type is `datetime64`
"""

# CONVERTING datetime column into datetime type (to strictly tell computer that the numbers here ARE datetime)
cars_data["ad_created"] = pd.to_datetime(cars_data["ad_created"])
cars_data["date_crawled"] = pd.to_datetime(cars_data["date_crawled"])
cars_data["last_seen"] = pd.to_datetime(cars_data["last_seen"])

# SANITY CHECK: check if data type is datetime
cars_data[["ad_created", "date_crawled", "last_seen"]].info()

"""### 4. Dari hasil observasi pada nomor 1, terlihat format data dari kolom price dan odometer tidak sesuai dengan representasi nilainya. Amati lebih detail nilai dari kolom-kolom tersebut. Kemudian ubahlah tipe datanya menjadi int64

> Note : Anda mungkin butuh untuk menyeragamkan format penulisan nilai pada kolom tersebut sebelum di konversi

---

4. From the results of observations in number 1, it can be seen that the data format of the price and odometer columns does not match the value representation. Observe in more detail the values of these columns. Then change the data type to int64

> Note: You may need to standardize the format of writing values in these columns before conversion
"""

# 4 # SAMAKAN FORMAT KOLOM PRICE DAN ODOMETER

# step 1 # format odometer diubah ==> hilangkan km dan $
cars_data["odometer"] = cars_data['odometer'].str.replace('km','').str.replace(',','')
cars_data["price"] = cars_data["price"].str.replace('$','').str.replace(',','')

# converting types into int
cars_data["odometer"] = cars_data["odometer"].astype(int)
cars_data["price"] = cars_data["price"].astype(int)

# sanity check
cars_data.head(5)

cars_data.dtypes

"""### 5. Dari hasil pengolahan diatas drop beberapa kolom dengan kriteria sebagai berikut:
    1. Untuk kolom yang bertipe string lakukan pengecekan jumlah data uniknya. Jika perbandingan data unik terlalu besar maka drop kolom tersebut
    2. Untuk kolom numeric, drop kolom yang tidak berisi informasi apapun (hanya berisi angka 0)
    3. Drop kolom yang informasinya unik disetiap baris datanya ("name") dan kolom yang memiliki banyak kategori namun tidak balance("postal_code")

---

5. From the processing results above, drop several columns with the following criteria:
     1. For columns of type string, check the number of unique data. If the unique data comparison is too large then drop the column
     2. For numeric column, drop column which does not contain any information (only contains number 0)
     3. Drop columns with unique information in each row of data ("name") and columns with multiple categories but not balance("postal_code")
"""

count_unique = cars_data.nunique()
count_unique

# selecting all object (str for panda) column, counting unique data, sort values
cars_data.select_dtypes(include='object').nunique().sort_values()

# dropping string/object with too many unique count
cars_data_dropobj = cars_data.drop(["name", "brand", "model"],axis=1)
cars_data_dropobj

# dropping null value from object
cars_data_dropna = cars_data.drop(["num_of_pictures"],axis=1)
cars_data_dropna

# drop name and postal_code
cars_data_dropnpo = cars_data.drop(["name", "postal_code"],axis=1)
cars_data_dropnpo

"""### 6. Dataset yang diolah memiliki outlier pada kolom price. untuk itu kita perlu menghapus kolom outlier dari datesetnya.
   1. Lakukan eksplorasi terhadap kolom price agar anda dapat mengidentifikasi outlier tersebut
   2. Untuk memudahkan pemrosesan, ditentukan nilai dari kolom price berkisar 500 sampai 40000. Hapus data yang nilai pricenya tidak masuk dalam rentang tersebut.

---

6. The processed dataset has outliers in the price column. for that we need to remove the outlier column from the dateset.
    1. Explore the price column so you can identify the outlier
    2. To facilitate processing, the value of the price column is determined to be in the range of 500 to 40000. Delete data whose price value does not fall within that range.

"""

# 6.1 # Viewing price column
cars_data['price'].sort_values()

# 6.2 # selecting car within the price range 500-40000
cars_data_pridrop = cars_data.loc[(cars_data["price"] >= 500) & (cars_data["price"] <= 40000)]
cars_data_pridrop["price"].sort_values()

"""### 7. Dari hasil observasi pada nomor 1. Terlihat beberapa kolom memiliki nilai NaN. Lakukan imputasi terhadap data NaN, dengan ketentuan:
    1. jika kolom tersebut bertipe object maka input dengan data mode-nya
    2. jika kolom tersebut bertipe numeric input dengan nilai mediannya

---

7. From the results of observations in number 1. It can be seen that several columns have NaN values. Perform imputation of NaN data, provided that:
     1. if the column is of type object then input it with the data mode
     2. if the column is of type numeric input with the median value
"""

# finding na data; use the one >0.000
missing_value_df = pd.DataFrame({"column_name": cars_data.columns,
                                 "percentage_missing": cars_data.isnull().sum()*100/len(cars_data)})
missing_value_df

# finding the mode of each column
vehicle_type_mode = cars_data["vehicle_type"].mode().astype(str)
gearbox_mode = cars_data["gearbox"].mode().astype(str)
model_mode = cars_data["model"].mode().astype(str)
fuel_type_mode = cars_data["fuel_type"].mode().astype(str)
unrepaired_damage_mode = cars_data["unrepaired_damage"].mode().astype(str)

# show me what the modes are
print(vehicle_type_mode)
print(gearbox_mode)
print(model_mode)
print(fuel_type_mode)
print(unrepaired_damage_mode)

# fill NA of each column
cars_data["vehicle_type"] = cars_data["vehicle_type"].fillna(str(vehicle_type_mode))
cars_data["gearbox"] = cars_data["gearbox"].fillna(str(gearbox_mode))
cars_data["model"] = cars_data["model"].fillna(str(model_mode))
cars_data["fuel_type"] = cars_data["fuel_type"].fillna(str(fuel_type_mode))
cars_data["unrepaired_damage"] = cars_data["unrepaired_damage"].fillna(str(unrepaired_damage_mode))

cars_data.info()

"""### 8. Lakukan normalisasi terhadap semua kolom yang bertipe Numeric (kecuali kolom target *'price'*).

---

8. Normalize all columns of type Numeric (except the target column *'price'*).
"""

normalized_df =(df - df. mean ())/ df. std () print(normalized_df)

cars_data_norm = normalize(cars_data[["power_ps", "odometer", "num_of_pictures"]])

# Inputkan Kode disini
cars_data_norm

"""### 9. Lakukan encoding untuk data kategorik, sehingga bertipe numeric. Perlu diperhatikan jika kolom tersebut bertipe ordinal pastikan proses encoding memerhatikan urutan dari tiap kategori.

> Note: lakukan eksplorasi terhadap data kategorik untuk menentukan mana kolom bertipe nominal atau ordinal

---

9. Perform encoding for categorical data, so that it is of numeric type. It should be noted that if the column is of type ordinal, make sure the encoding process pays attention to the order of each category.

> Note: explore categorical data to determine which column is of nominal or ordinal type
"""

pd.Categorical(cars_data["model"]).codes

categorical = [col for col in cars_data.columns if cars_data[col].dtype == 'object']
cars_data[categorical].head()

cat_columns = cars_data.select_dtypes(["object"]).columns

# Inputkan Kode disini
class CategoricalFeatures:
    def __init__(self, df, categorical_features, encoding_type, handle_na=False):
        """
        df: pandas dataframe
        categorical_features: list of categorical column names e.g. nominal, ordinal data type
        encoding_type: type of encoding e.g. label, one_hot
        handle_na: handle the missing values or not e.g. True/False
        """
        self.df = df
        self.cat_feats = categorical_features
        self.enc_type  = encoding_type
        self.handle_na = handle_na
        self.label_encoders = dict()
        self.one_hot_encoders = None
        if self.handle_na is True:
            for c in self.cat_feats:
                self.df.loc[:, c] = self.df.loc[:, c].astype(str).fillna("-9999999")
        self.output_df = self.df.copy(deep=True)

    def _label_encoding(self):
        for c in self.cat_feats:
            lbl = preprocessing.LabelEncoder()
            lbl.fit(self.df[c].values)
            self.output_df.loc[:, c] = lbl.transform(self.df[c].values)
            self.label_encoders[c] = lbl
        return self.output_df

    def _one_hot_encoding(self):
        one_hot_encoders = preprocessing.OneHotEncoder()
        one_hot_encoders.fit(self.df[self.cat_feats].values)
        dum_ct = pd.DataFrame(one_hot_encoders.transform(self.df[self.cat_feats].values).toarray(), index = self.df.index)
        self.output_df = self.df.drop(columns=self.cat_feats, axis=1).join(dum_ct) 
        return self.output_df
                        
    def _get_dummies(self):
        self.output_df = pd.get_dummies(self.df, columns=self.cat_feats, dummy_na=False)
        return self.output_df

    def fit_transform(self):
        if self.enc_type == "label":
            return self._label_encoding()
        elif self.enc_type == "one_hot":   
            return self._one_hot_encoding()
        elif self.enc_type == "get_dum":
            return self._get_dummies()
        else:
            raise Exception("Encoding type not supported!")

cars_data_encoding = CategoricalFeatures(cars_data[categorical], categorical, encoding_type="get_dum")
cars_data_encoding.fit_transform()

"""### 10. Buatlah script pipeline pengolahan data yang telah dilakukan. Kemudian simpan kedalam sebuah repository di akun Github anda. Lampirkan link repository di bawah

---

10. Make a data processing pipeline script that has been done. Then save it to a repository on your Github account. Attach the repository link below
"""

https://github.com/lrsprbw/larasati-gygK-wrangling-4